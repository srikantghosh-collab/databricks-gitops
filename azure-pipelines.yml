trigger:
- main

variables:
  PYTHON_VERSION: '3.10'

stages:

# ======================
# STAGE 1: DETECT
# ======================
- stage: Detect
  displayName: "Detect DDL Changes"
  jobs:
  - job: detect
    displayName: "Detection Job"
    pool:
      vmImage: ubuntu-latest
    steps:
    - checkout: self
      fetchDepth: 0

    - task: UsePythonVersion@0
      inputs:
        versionSpec: $(PYTHON_VERSION)

    # IMPORTANT: step name is required to expose output variables
    - script: |
        python scripts/detect_ddl.py
      name: detectddl
      displayName: "Detect DDL"

    - script: |
        python scripts/detect_revert.py
      name: detectrevert
      displayName: "Detect Git Revert"

    - task: PublishPipelineArtifact@1
      inputs:
       targetPath: '$(System.DefaultWorkingDirectory)/ddl_output.json'
       artifact: 'ddlartifact'
       publishLocation: 'pipeline'
      displayName: "Publish DDL Artifact"

# ======================
# STAGE 2: AI CLASSIFICATION
# ======================
- stage: AI
  displayName: "AI DDL Classification"
  dependsOn: Detect
  jobs:
  - job: ai
    displayName: "AI Job"
    pool:
      vmImage: ubuntu-latest
    steps:
    - checkout: self

    - task: DownloadPipelineArtifact@2
      inputs:
        artifact: 'ddlartifact'
        path: .
      displayName: "Download DDL Artifact"

    - task: UsePythonVersion@0
      inputs:
        versionSpec: $(PYTHON_VERSION)

    - script: |
        python -m pip install "openai>=1.30.0"
      displayName: "Install AzureOpenAI"

    - script: |
        python scripts/classify_ddl_ai.py
      name: SetOutput
      displayName: "Run AI Classification"
      env:
        AZURE_OPENAI_KEY: $(AZURE_OPENAI_KEY)
        AZURE_OPENAI_ENDPOINT: $(AZURE_OPENAI_ENDPOINT)
        AZURE_DEPLOYMENT_NAME: $(AZURE_DEPLOYMENT_NAME)

# ==================================
# STAGE 3: Generate Rollback Script
# ==================================    

- stage: RollbackGen
  displayName: "Generate Rollback Script"
  dependsOn: AI
  jobs:
  - job: rollback
    pool:
      vmImage: ubuntu-latest
    steps:
    - checkout: self

    - task: DownloadPipelineArtifact@2
      inputs:
        artifact: 'ddlartifact'
        path: .

    - task: UsePythonVersion@0
      inputs:
        versionSpec: '3.10'

    - script: |
        python scripts/rollback_generator.py
      displayName: "Generate Rollback"

    - task: PublishPipelineArtifact@1
      inputs:
        targetPath: rollback.sql
        artifact: rollbackartifact
      displayName: "Publish Rollback Artifact"



# ======================
# STAGE 4: MANUAL APPROVAL (ONLY FOR DROP)
# ======================
- stage: Approval
  displayName: "Manual Approval for DROP"
  dependsOn: AI
  # Runs ONLY when IS_DROP == true
  condition: |
    and(
    succeeded(),
    eq(dependencies.AI.outputs['ai.SetOutput.IS_DROP'], 'true')
    )

  jobs:
  - job: approval
    displayName: "Approval Gate"
    pool: server
    steps:
    - task: ManualValidation@0
      inputs:
        instructions: "DROP TABLE detected. Please approve to continue."
        timeoutInMinutes: 1440


# ======================
# STAGE 5: EXECUTE
# ======================
- stage: Execute
  displayName: "Execute DDL"
  dependsOn:
    - AI
    - RollbackGen
    - Approval
  # KEY LOGIC:
  # - CREATE / ALTER (IS_DROP=false) -> run immediately
  # - DROP (IS_DROP=true) -> run ONLY after approval
  condition: |
    and(
      succeeded('AI'),
      or(
        eq(dependencies.AI.outputs['ai.SetOutput.IS_DROP'], 'false'),
        succeeded('Approval')
      )
    )
  jobs:
  - job: execute
    displayName: "Execute Job"
    pool:
      vmImage: ubuntu-latest
    steps:
    - checkout: self

    - task: UsePythonVersion@0
      inputs:
        versionSpec: $(PYTHON_VERSION)

    - script: |
        python -m pip install --upgrade pip
        python -m pip install databricks-sql-connector
      displayName: "Install Databricks SQL Connector"

    - script: |
        python scripts/execute_ddl.py
      displayName: "Execute DDL"
      env:
        DATABRICKS_HOST: $(Databricks_Host)
        DATABRICKS_TOKEN: $(Databricks_Token)
        DATABRICKS_HTTP_PATH: $(Databricks_HTTP_Path)

    - script: |
       if [ -f rollback_metadata.json ]; then
        echo "##vso[task.setvariable variable=HAS_METADATA]true"
       else
        echo "##vso[task.setvariable variable=HAS_METADATA]false"
       fi
      displayName: "Check rollback metadata"

    - task: PublishPipelineArtifact@1
      condition: eq(variables.HAS_METADATA, 'true')
      inputs:
       targetPath: 'rollback_metadata.json'
       artifact: 'rollbackmeta'
      displayName: "Publish Rollback Metadata"

# ======================
# STAGE 6: RECONCILE
# ======================
- stage: Reconcile
  displayName: "Schema Reconciliation"
  dependsOn: Execute
  condition: succeeded('Execute')
  jobs:
  - job: reconcile
    displayName: "Reconcile Job"
    pool:
      vmImage: ubuntu-latest
    steps:
    - checkout: self

    - task: UsePythonVersion@0
      inputs:
        versionSpec: '3.10'

    - script: |
        pip install databricks-sql-connector pyyaml
        python scripts/reconcile_schema.py
      displayName: "Run Reconciliation"
      env:
        DATABRICKS_HOST: $(Databricks_Host)
        DATABRICKS_TOKEN: $(Databricks_Token)
        DATABRICKS_HTTP_PATH: $(Databricks_HTTP_Path)

# ======================
# STAGE 7: AUTO ROLLBACK (PHASE-2)
# ======================
- stage: AutoRollback
  displayName: "Auto Rollback from Backup"
  dependsOn: Detect
  condition: eq(dependencies.Detect.outputs['detect.detectrevert.IS_REVERT'], 'true')

  jobs:
  - job: rollback
    displayName: "Rollback Job"
    pool:
      vmImage: ubuntu-latest
    steps:
    - checkout: self

    - task: DownloadPipelineArtifact@2
      inputs:
        artifact: rollbackmeta
        path: .

    - task: UsePythonVersion@0
      inputs:
        versionSpec: '3.10'

    - script: |
        python -m pip install databricks-sql-connector
      displayName: "Install Databricks Connector"

    - script: |
        python scripts/restore_from_backup.py
      displayName: "Restore from Backup"
      env:
        DATABRICKS_HOST: $(Databricks_Host)
        DATABRICKS_TOKEN: $(Databricks_Token)
        DATABRICKS_HTTP_PATH: $(Databricks_HTTP_Path)

